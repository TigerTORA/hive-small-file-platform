name: Deploy Staging (Self-hosted)

on:
  workflow_dispatch:
    inputs:
      version:
        description: 'Image version tag (e.g., 1.0.2)'
        required: true
        default: '1.0.2'

permissions:
  contents: read

jobs:
  deploy:
    runs-on: [self-hosted, staging]
    env:
      VERSION: ${{ inputs.version }}
      IMAGE_OWNER: ${{ vars.IMAGE_OWNER || github.repository_owner }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Ensure docker compose plugin (v2)
        shell: bash
        run: |
          set -e
          mkdir -p ~/.docker/cli-plugins
          if ! docker compose version >/dev/null 2>&1; then
            curl -L -o ~/.docker/cli-plugins/docker-compose \
              https://github.com/docker/compose/releases/download/v2.27.0/docker-compose-linux-x86_64
            chmod +x ~/.docker/cli-plugins/docker-compose
          fi
          docker compose version

      - name: Write compose and env files (if missing)
        shell: bash
        run: |
          set -e
          cd /opt && mkdir -p hive-platform && cd hive-platform
          if [ ! -f docker-compose.prod.yml ]; then
            cat > docker-compose.prod.yml <<'EOF'
          version: '3.8'
          services:
            postgres:
              image: postgres:14
              container_name: hive-platform-db
              environment:
                POSTGRES_DB: hive_small_file_db
                POSTGRES_USER: postgres
                POSTGRES_PASSWORD: postgres
              volumes:
                - postgres_data:/var/lib/postgresql/data
              ports: [ "5432:5432" ]
              networks: [ hive-platform ]
            redis:
              image: redis:6-alpine
              container_name: hive-platform-redis
              ports: [ "6379:6379" ]
              volumes:
                - redis_data:/data
              networks: [ hive-platform ]
            api:
              image: ghcr.io/${{ env.IMAGE_OWNER }}/hive-small-file-api:${{ env.VERSION }}
              container_name: hive-platform-api
              env_file: [ backend/.env ]
              environment:
                - SENTRY_ENVIRONMENT=staging
                - AUTO_CREATE_SCHEMA=false
                - RELOAD=false
              depends_on: [ postgres, redis ]
              ports: [ "8000:8000" ]
              networks: [ hive-platform ]
            celery-worker:
              image: ghcr.io/${{ env.IMAGE_OWNER }}/hive-small-file-api:${{ env.VERSION }}
              container_name: hive-platform-worker
              command: celery -A app.scheduler.celery_app worker --loglevel=info --concurrency=4
              env_file: [ backend/.env ]
              environment: [ "SENTRY_ENVIRONMENT=staging" ]
              depends_on: [ postgres, redis ]
              networks: [ hive-platform ]
            celery-beat:
              image: ghcr.io/${{ env.IMAGE_OWNER }}/hive-small-file-api:${{ env.VERSION }}
              container_name: hive-platform-beat
              command: celery -A app.scheduler.celery_app beat --loglevel=info
              env_file: [ backend/.env ]
              environment: [ "SENTRY_ENVIRONMENT=staging" ]
              depends_on: [ postgres, redis ]
              networks: [ hive-platform ]
            frontend:
              image: ghcr.io/${{ env.IMAGE_OWNER }}/hive-small-file-frontend:${{ env.VERSION }}
              container_name: hive-platform-frontend
              depends_on: [ api ]
              ports: [ "80:80" ]
              networks: [ hive-platform ]
          volumes: { postgres_data: {}, redis_data: {} }
          networks: { hive-platform: { driver: bridge } }
          EOF
          fi
          mkdir -p backend frontend
          if [ ! -f backend/.env ]; then
            cat > backend/.env <<'EOF'
          SERVER_HOST=0.0.0.0
          SERVER_PORT=8000
          RELOAD=false
          DATABASE_URL=postgresql://postgres:postgres@postgres:5432/hive_small_file_db
          REDIS_URL=redis://redis:6379/0
          CELERY_BROKER_URL=redis://redis:6379/1
          CELERY_RESULT_BACKEND=redis://redis:6379/2
          SECRET_KEY=change-me-in-staging
          ACCESS_TOKEN_EXPIRE_MINUTES=1440
          DEFAULT_HIVE_HOST=localhost
          DEFAULT_HIVE_PORT=10000
          DEFAULT_HDFS_URL=http://namenode:9870/webhdfs/v1
          SMALL_FILE_THRESHOLD=134217728
          SENTRY_DSN=
          SENTRY_ENVIRONMENT=staging
          AUTO_CREATE_SCHEMA=false
          DEMO_MODE=false
          EOF
          fi
          if [ ! -f frontend/.env ]; then
            echo 'VITE_API_BASE_URL=/api/v1' > frontend/.env
          fi
          ls -lh docker-compose.prod.yml backend/.env frontend/.env

      - name: Build Images on Runner
        shell: bash
        run: |
          echo "=== 在Runner云端构建镜像 ==="

          # 构建API镜像并推送到Docker Hub
          cd ${{ github.workspace }}/backend
          echo "构建API镜像..."
          docker build -t hiveplatform/api:${{ env.VERSION }} . || { echo "API构建失败"; exit 1; }

          # 构建前端镜像
          cd ${{ github.workspace }}/frontend
          echo "构建前端镜像..."
          docker build -t hiveplatform/frontend:${{ env.VERSION }} . || { echo "前端构建失败"; exit 1; }

          # 登录Docker Hub并推送
          echo "${{ secrets.DOCKER_HUB_TOKEN }}" | docker login -u "${{ secrets.DOCKER_HUB_USERNAME }}" --password-stdin || echo "Docker Hub登录失败，使用本地镜像"

          # 推送镜像（忽略失败）
          docker push hiveplatform/api:${{ env.VERSION }} || echo "API镜像推送失败，继续..."
          docker push hiveplatform/frontend:${{ env.VERSION }} || echo "前端镜像推送失败，继续..."

          echo "=== 镜像构建完成 ==="

      - name: Deploy to 105 Server
        shell: bash
        run: |
          echo "=== SSH到105机器进行部署 ==="

          # 创建部署脚本
          cat > deploy_script.sh <<'DEPLOY_EOF'
          #!/bin/bash
          set -e

          echo "=== 在105机器上执行部署 ==="
          cd /opt && mkdir -p hive-platform && cd hive-platform

          # 停止旧服务
          docker stop hive-platform-api hive-platform-frontend hive-platform-worker hive-platform-beat >/dev/null 2>&1 || true
          docker rm hive-platform-api hive-platform-frontend hive-platform-worker hive-platform-beat >/dev/null 2>&1 || true

          # 创建环境文件（如果不存在）
          mkdir -p backend frontend
          if [ ! -f backend/.env ]; then
            cat > backend/.env <<'ENV_EOF'
          SERVER_HOST=0.0.0.0
          SERVER_PORT=8000
          RELOAD=false
          DATABASE_URL=postgresql://postgres:postgres@localhost:5432/hive_small_file_db
          REDIS_URL=redis://localhost:6379/0
          CELERY_BROKER_URL=redis://localhost:6379/1
          CELERY_RESULT_BACKEND=redis://localhost:6379/2
          SECRET_KEY=change-me-in-staging
          ACCESS_TOKEN_EXPIRE_MINUTES=1440
          DEFAULT_HIVE_HOST=localhost
          DEFAULT_HIVE_PORT=10000
          DEFAULT_HDFS_URL=http://namenode:9870/webhdfs/v1
          SMALL_FILE_THRESHOLD=134217728
          SENTRY_DSN=
          SENTRY_ENVIRONMENT=staging
          AUTO_CREATE_SCHEMA=false
          DEMO_MODE=false
          ENV_EOF
          fi

          # 确保数据库运行
          docker ps | grep postgres || docker run -d --name postgres-db -e POSTGRES_DB=hive_small_file_db -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=postgres -p 5432:5432 postgres:14 || echo "数据库启动跳过"
          docker ps | grep redis || docker run -d --name redis-cache -p 6379:6379 redis:6-alpine || echo "Redis启动跳过"

          sleep 10

          # 拉取并启动应用镜像（优先使用Docker Hub，失败则跳过）
          docker pull hiveplatform/api:VERSION_PLACEHOLDER || echo "API镜像拉取失败"
          docker pull hiveplatform/frontend:VERSION_PLACEHOLDER || echo "前端镜像拉取失败"

          # 启动API服务
          docker run -d --name hive-platform-api \
            --env-file backend/.env \
            -e SENTRY_ENVIRONMENT=staging \
            -p 8000:8000 --restart unless-stopped \
            hiveplatform/api:VERSION_PLACEHOLDER || echo "API启动失败"

          # 启动前端服务
          docker run -d --name hive-platform-frontend \
            -p 80:80 --restart unless-stopped \
            hiveplatform/frontend:VERSION_PLACEHOLDER || echo "前端启动失败"

          echo "=== 105机器部署完成 ==="
          docker ps | grep hive-platform || echo "没有hive-platform容器运行"
          DEPLOY_EOF

          # 替换版本号
          sed -i "s/VERSION_PLACEHOLDER/${{ env.VERSION }}/g" deploy_script.sh

          # 执行SSH部署（如果SSH配置可用）
          if command -v ssh >/dev/null 2>&1; then
            chmod +x deploy_script.sh
            # 这里需要SSH密钥配置才能工作
            # scp deploy_script.sh root@192.168.0.105:/tmp/
            # ssh root@192.168.0.105 "bash /tmp/deploy_script.sh"
            echo "SSH部署脚本已准备好: deploy_script.sh"
            echo "请手动执行: scp deploy_script.sh root@192.168.0.105:/tmp/ && ssh root@192.168.0.105 'bash /tmp/deploy_script.sh'"
          else
            echo "SSH不可用，请手动将部署脚本复制到105机器执行"
          fi

      - name: DB migration
        shell: bash
        run: |
          cd /opt/hive-platform
          sleep 10 || true
          docker compose -f docker-compose.prod.yml exec api alembic upgrade head || true

      - name: Health checks
        shell: bash
        run: |
          echo 'API:'; curl -s http://127.0.0.1:8000/health || true
          echo 'FE :'; curl -s http://127.0.0.1/health || true

