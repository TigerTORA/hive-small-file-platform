name: Deploy Staging (Self-hosted)

on:
  workflow_dispatch:
    inputs:
      version:
        description: 'Image version tag (e.g., 1.0.2)'
        required: true
        default: '1.0.2'

permissions:
  contents: read

jobs:
  deploy:
    runs-on: [self-hosted, staging]
    env:
      VERSION: ${{ inputs.version }}
      IMAGE_OWNER: ${{ vars.IMAGE_OWNER || github.repository_owner }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Ensure docker compose plugin (v2)
        shell: bash
        run: |
          set -e
          mkdir -p ~/.docker/cli-plugins
          if ! docker compose version >/dev/null 2>&1; then
            curl -L -o ~/.docker/cli-plugins/docker-compose \
              https://github.com/docker/compose/releases/download/v2.27.0/docker-compose-linux-x86_64
            chmod +x ~/.docker/cli-plugins/docker-compose
          fi
          docker compose version

      - name: Write compose and env files (if missing)
        shell: bash
        run: |
          set -e
          cd /opt && mkdir -p hive-platform && cd hive-platform
          if [ ! -f docker-compose.prod.yml ]; then
            cat > docker-compose.prod.yml <<'EOF'
          version: '3.8'
          services:
            postgres:
              image: postgres:14
              container_name: hive-platform-db
              environment:
                POSTGRES_DB: hive_small_file_db
                POSTGRES_USER: postgres
                POSTGRES_PASSWORD: postgres
              volumes:
                - postgres_data:/var/lib/postgresql/data
              ports: [ "5432:5432" ]
              networks: [ hive-platform ]
            redis:
              image: redis:6-alpine
              container_name: hive-platform-redis
              ports: [ "6379:6379" ]
              volumes:
                - redis_data:/data
              networks: [ hive-platform ]
            api:
              image: ghcr.io/${{ env.IMAGE_OWNER }}/hive-small-file-api:${{ env.VERSION }}
              container_name: hive-platform-api
              env_file: [ backend/.env ]
              environment:
                - SENTRY_ENVIRONMENT=staging
                - AUTO_CREATE_SCHEMA=false
                - RELOAD=false
              depends_on: [ postgres, redis ]
              ports: [ "8000:8000" ]
              networks: [ hive-platform ]
            celery-worker:
              image: ghcr.io/${{ env.IMAGE_OWNER }}/hive-small-file-api:${{ env.VERSION }}
              container_name: hive-platform-worker
              command: celery -A app.scheduler.celery_app worker --loglevel=info --concurrency=4
              env_file: [ backend/.env ]
              environment: [ "SENTRY_ENVIRONMENT=staging" ]
              depends_on: [ postgres, redis ]
              networks: [ hive-platform ]
            celery-beat:
              image: ghcr.io/${{ env.IMAGE_OWNER }}/hive-small-file-api:${{ env.VERSION }}
              container_name: hive-platform-beat
              command: celery -A app.scheduler.celery_app beat --loglevel=info
              env_file: [ backend/.env ]
              environment: [ "SENTRY_ENVIRONMENT=staging" ]
              depends_on: [ postgres, redis ]
              networks: [ hive-platform ]
            frontend:
              image: ghcr.io/${{ env.IMAGE_OWNER }}/hive-small-file-frontend:${{ env.VERSION }}
              container_name: hive-platform-frontend
              depends_on: [ api ]
              ports: [ "80:80" ]
              networks: [ hive-platform ]
          volumes: { postgres_data: {}, redis_data: {} }
          networks: { hive-platform: { driver: bridge } }
          EOF
          fi
          mkdir -p backend frontend
          if [ ! -f backend/.env ]; then
            cat > backend/.env <<'EOF'
          SERVER_HOST=0.0.0.0
          SERVER_PORT=8000
          RELOAD=false
          DATABASE_URL=postgresql://postgres:postgres@postgres:5432/hive_small_file_db
          REDIS_URL=redis://redis:6379/0
          CELERY_BROKER_URL=redis://redis:6379/1
          CELERY_RESULT_BACKEND=redis://redis:6379/2
          SECRET_KEY=change-me-in-staging
          ACCESS_TOKEN_EXPIRE_MINUTES=1440
          DEFAULT_HIVE_HOST=localhost
          DEFAULT_HIVE_PORT=10000
          DEFAULT_HDFS_URL=http://namenode:9870/webhdfs/v1
          SMALL_FILE_THRESHOLD=134217728
          SENTRY_DSN=
          SENTRY_ENVIRONMENT=staging
          AUTO_CREATE_SCHEMA=false
          DEMO_MODE=false
          EOF
          fi
          if [ ! -f frontend/.env ]; then
            echo 'VITE_API_BASE_URL=/api/v1' > frontend/.env
          fi
          ls -lh docker-compose.prod.yml backend/.env frontend/.env

      - name: Build and Deploy
        shell: bash
        run: |
          cd /opt/hive-platform
          echo "=== 检查现有服务状态 ==="
          docker ps | grep hive-platform || echo "没有运行中的hive-platform容器"

          echo "=== 检查现有镜像 ==="
          docker images | grep -E "(postgres|redis)" || echo "数据库镜像不存在"

          echo "=== 停止旧服务（忽略错误） ==="
          docker stop hive-platform-api hive-platform-frontend hive-platform-worker hive-platform-beat >/dev/null 2>&1 || true
          docker rm hive-platform-api hive-platform-frontend hive-platform-worker hive-platform-beat >/dev/null 2>&1 || true

          echo "=== 确保数据库服务运行 ==="
          # 检查postgres是否已运行
          if ! docker ps | grep hive-platform-db >/dev/null 2>&1; then
            echo "启动postgres数据库"
            # 尝试使用已存在的镜像，如果不存在就跳过
            if docker images | grep postgres >/dev/null 2>&1; then
              docker run -d --name hive-platform-db \
                -e POSTGRES_DB=hive_small_file_db -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=postgres \
                -p 5432:5432 -v hive_postgres_data:/var/lib/postgresql/data --restart unless-stopped postgres:14 || echo "postgres启动失败，继续..."
            else
              echo "postgres镜像不存在，跳过"
            fi
          else
            echo "postgres数据库已运行"
          fi

          # 检查redis是否已运行
          if ! docker ps | grep hive-platform-redis >/dev/null 2>&1; then
            echo "启动redis"
            if docker images | grep redis >/dev/null 2>&1; then
              docker run -d --name hive-platform-redis \
                -p 6379:6379 -v hive_redis_data:/data --restart unless-stopped redis:6-alpine || echo "redis启动失败，继续..."
            else
              echo "redis镜像不存在，跳过"
            fi
          else
            echo "redis已运行"
          fi

          echo "=== 等待数据库就绪 ==="
          sleep 10

          echo "=== 构建并启动API服务 ==="
          cd ${{ github.workspace }}/backend
          docker build -t hive-api:local . || { echo "API构建失败"; exit 1; }
          docker run -d --name hive-platform-api \
            --env-file /opt/hive-platform/backend/.env \
            -e SENTRY_ENVIRONMENT=staging -e AUTO_CREATE_SCHEMA=false -e RELOAD=false \
            -p 8000:8000 --restart unless-stopped hive-api:local || { echo "API启动失败"; exit 1; }

          echo "=== 构建并启动前端服务 ==="
          cd ${{ github.workspace }}/frontend
          docker build -t hive-frontend:local . || { echo "前端构建失败"; exit 1; }
          docker run -d --name hive-platform-frontend \
            -p 80:80 --restart unless-stopped hive-frontend:local || { echo "前端启动失败"; exit 1; }

          echo "=== 启动后台任务 ==="
          docker run -d --name hive-platform-worker \
            --env-file /opt/hive-platform/backend/.env -e SENTRY_ENVIRONMENT=staging \
            --restart unless-stopped hive-api:local \
            celery -A app.scheduler.celery_app worker --loglevel=info --concurrency=4 || echo "worker启动失败，继续..."

          docker run -d --name hive-platform-beat \
            --env-file /opt/hive-platform/backend/.env -e SENTRY_ENVIRONMENT=staging \
            --restart unless-stopped hive-api:local \
            celery -A app.scheduler.celery_app beat --loglevel=info || echo "beat启动失败，继续..."

          echo "=== 部署完成，检查状态 ==="
          docker ps | grep hive-platform || echo "没有hive-platform容器在运行"

      - name: DB migration
        shell: bash
        run: |
          cd /opt/hive-platform
          sleep 10 || true
          docker compose -f docker-compose.prod.yml exec api alembic upgrade head || true

      - name: Health checks
        shell: bash
        run: |
          echo 'API:'; curl -s http://127.0.0.1:8000/health || true
          echo 'FE :'; curl -s http://127.0.0.1/health || true

