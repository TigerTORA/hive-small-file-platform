name: Deploy Staging (Self-hosted)

on:
  workflow_dispatch:
    inputs:
      version:
        description: 'Image version tag (e.g., 1.0.2)'
        required: true
        default: '1.0.2'

permissions:
  contents: read

jobs:
  deploy:
    runs-on: [self-hosted, staging]
    env:
      VERSION: ${{ inputs.version }}
      IMAGE_OWNER: ${{ vars.IMAGE_OWNER || github.repository_owner }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        shell: bash
        run: |
          echo "=== 安装Node.js环境 ==="
          # 检查是否已安装Node.js
          if command -v node >/dev/null 2>&1; then
            echo "Node.js已安装: $(node --version)"
            echo "npm版本: $(npm --version)"
          else
            echo "安装Node.js..."
            # 使用NodeSource安装Node.js 20（LTS）
            curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash - || echo "NodeSource脚本执行失败"
            sudo apt-get install -y nodejs || echo "apt-get安装失败"

            # 如果还是没有，尝试使用snap安装
            if ! command -v node >/dev/null 2>&1; then
              echo "尝试使用snap安装Node.js..."
              sudo snap install node --classic || echo "snap安装失败"
            fi

            # 如果还是没有，下载二进制版本
            if ! command -v node >/dev/null 2>&1; then
              echo "下载Node.js二进制版本..."
              cd /tmp
              curl -fsSL https://nodejs.org/dist/v18.18.0/node-v18.18.0-linux-x64.tar.xz -o node.tar.xz
              tar -xf node.tar.xz
              sudo cp -r node-v18.18.0-linux-x64/* /usr/local/
            fi
          fi

          # 验证安装
          node --version && npm --version

      - name: Configure Docker Registry Mirrors
        shell: bash
        run: |
          set -e
          echo "=== 配置Docker国内镜像源 ==="

          # 创建docker配置目录
          sudo mkdir -p /etc/docker

          # 配置国内镜像源
          sudo tee /etc/docker/daemon.json > /dev/null <<'EOF'
          {
            "registry-mirrors": [
              "https://docker.m.daocloud.io",
              "https://mirror.ccs.tencentyun.com",
              "https://hub-mirror.c.163.com",
              "https://reg-mirror.qiniu.com",
              "https://dockerhub.azk8s.cn"
            ],
            "storage-driver": "overlay2"
          }
          EOF

          echo "Docker镜像源配置完成:"
          cat /etc/docker/daemon.json

          # 重启docker服务（podman环境可能不需要）
          sudo systemctl daemon-reload || echo "systemctl不可用，跳过"
          sudo systemctl restart docker || echo "docker服务重启跳过"

          echo "=== 验证镜像源配置 ==="
          docker info | grep -A 10 "Registry Mirrors" || echo "podman环境，配置已应用"

          echo "=== 配置Podman镜像源（如果使用podman） ==="
          # 创建podman配置目录
          mkdir -p ~/.config/containers

          # 配置podman镜像源 - 使用v2格式
          tee ~/.config/containers/registries.conf > /dev/null <<'EOF'
          unqualified-search-registries = ["docker.io"]

          [[registry]]
          prefix = "docker.io"
          location = "docker.io"

          [[registry.mirror]]
          location = "docker.m.daocloud.io"

          [[registry.mirror]]
          location = "mirror.ccs.tencentyun.com"

          [[registry.mirror]]
          location = "hub-mirror.c.163.com"

          [[registry.mirror]]
          location = "reg-mirror.qiniu.com"
          EOF

          echo "Podman镜像源配置完成:"
          cat ~/.config/containers/registries.conf || echo "配置文件不存在"

      - name: Ensure docker compose plugin (v2)
        shell: bash
        run: |
          set -e
          mkdir -p ~/.docker/cli-plugins
          if ! docker compose version >/dev/null 2>&1; then
            curl -L -o ~/.docker/cli-plugins/docker-compose \
              https://github.com/docker/compose/releases/download/v2.27.0/docker-compose-linux-x86_64
            chmod +x ~/.docker/cli-plugins/docker-compose
          fi
          docker compose version

      - name: Write compose and env files (if missing)
        shell: bash
        run: |
          set -e
          cd /opt && mkdir -p hive-platform && cd hive-platform
          if [ ! -f docker-compose.prod.yml ]; then
            cat > docker-compose.prod.yml <<'EOF'
          version: '3.8'
          services:
            postgres:
              image: postgres:14
              container_name: hive-platform-db
              environment:
                POSTGRES_DB: hive_small_file_db
                POSTGRES_USER: postgres
                POSTGRES_PASSWORD: postgres
              volumes:
                - postgres_data:/var/lib/postgresql/data
              ports: [ "5432:5432" ]
              networks: [ hive-platform ]
            redis:
              image: redis:6-alpine
              container_name: hive-platform-redis
              ports: [ "6379:6379" ]
              volumes:
                - redis_data:/data
              networks: [ hive-platform ]
            api:
              image: ghcr.io/${{ env.IMAGE_OWNER }}/hive-small-file-api:${{ env.VERSION }}
              container_name: hive-platform-api
              env_file: [ backend/.env ]
              environment:
                - SENTRY_ENVIRONMENT=staging
                - AUTO_CREATE_SCHEMA=false
                - RELOAD=false
              depends_on: [ postgres, redis ]
              ports: [ "8000:8000" ]
              networks: [ hive-platform ]
            celery-worker:
              image: ghcr.io/${{ env.IMAGE_OWNER }}/hive-small-file-api:${{ env.VERSION }}
              container_name: hive-platform-worker
              command: celery -A app.scheduler.celery_app worker --loglevel=info --concurrency=4
              env_file: [ backend/.env ]
              environment: [ "SENTRY_ENVIRONMENT=staging" ]
              depends_on: [ postgres, redis ]
              networks: [ hive-platform ]
            celery-beat:
              image: ghcr.io/${{ env.IMAGE_OWNER }}/hive-small-file-api:${{ env.VERSION }}
              container_name: hive-platform-beat
              command: celery -A app.scheduler.celery_app beat --loglevel=info
              env_file: [ backend/.env ]
              environment: [ "SENTRY_ENVIRONMENT=staging" ]
              depends_on: [ postgres, redis ]
              networks: [ hive-platform ]
            frontend:
              image: ghcr.io/${{ env.IMAGE_OWNER }}/hive-small-file-frontend:${{ env.VERSION }}
              container_name: hive-platform-frontend
              depends_on: [ api ]
              ports: [ "80:80" ]
              networks: [ hive-platform ]
          volumes: { postgres_data: {}, redis_data: {} }
          networks: { hive-platform: { driver: bridge } }
          EOF
          fi
          mkdir -p backend frontend
          if [ ! -f backend/.env ]; then
            cat > backend/.env <<'EOF'
          SERVER_HOST=0.0.0.0
          SERVER_PORT=8000
          RELOAD=false
          DATABASE_URL=postgresql://postgres:postgres@postgres:5432/hive_small_file_db
          REDIS_URL=redis://redis:6379/0
          CELERY_BROKER_URL=redis://redis:6379/1
          CELERY_RESULT_BACKEND=redis://redis:6379/2
          SECRET_KEY=change-me-in-staging
          ACCESS_TOKEN_EXPIRE_MINUTES=1440
          DEFAULT_HIVE_HOST=localhost
          DEFAULT_HIVE_PORT=10000
          DEFAULT_HDFS_URL=http://namenode:9870/webhdfs/v1
          SMALL_FILE_THRESHOLD=134217728
          SENTRY_DSN=
          SENTRY_ENVIRONMENT=staging
          AUTO_CREATE_SCHEMA=false
          DEMO_MODE=false
          EOF
          fi
          if [ ! -f frontend/.env ]; then
            echo 'VITE_API_BASE_URL=/api/v1' > frontend/.env
          fi
          ls -lh docker-compose.prod.yml backend/.env frontend/.env

      - name: Deploy with Docker Compose (Persistent)
        shell: bash
        run: |
          echo "=== 使用Docker Compose持久化部署 ==="
          cd /opt/hive-platform

          # 构建本地镜像
          echo "=== 构建应用镜像 ==="
          cd ${{ github.workspace }}/backend
          docker build -t ghcr.io/tigertora/hive-small-file-api:${{ env.VERSION }} .

          cd ${{ github.workspace }}/frontend
          echo "安装前端依赖..."
          export PUPPETEER_SKIP_DOWNLOAD=true
          npm install --registry=https://registry.npmmirror.com
          echo "构建前端..."
          npm run build
          echo "构建前端镜像..."
          docker build -t ghcr.io/tigertora/hive-small-file-frontend:${{ env.VERSION }} .

          # 返回部署目录，使用compose部署
          cd /opt/hive-platform
          echo "=== 使用Docker Compose部署 ==="
          docker compose -f docker-compose.prod.yml down || true
          docker compose -f docker-compose.prod.yml up -d

          echo "=== 等待服务启动 ==="
          sleep 30

          echo "=== 检查服务状态 ==="
          docker compose -f docker-compose.prod.yml ps

          echo "=== API健康检查 ==="
          for i in {1..5}; do
            echo "第 $i 次API健康检查..."
            if curl -s --connect-timeout 5 --max-time 10 http://localhost:8000/health; then
              echo "✅ API服务响应正常！"
              break
            else
              echo "⏳ API服务还未就绪，继续等待... ($i/5)"
              sleep 10
            fi
          done

          echo ""
          echo "🎉 ===== 部署完成状态 ====="
          echo "🖥️  yun主机IP: 115.190.156.197"
          echo "🔗 API健康检查: http://115.190.156.197:8000/health"
          echo "🌐 前端应用: http://115.190.156.197/"
          echo "📊 Hive小文件治理平台已就绪！"

      - name: DB migration
        shell: bash
        run: |
          cd /opt/hive-platform
          sleep 10 || true
          docker compose -f docker-compose.prod.yml exec api alembic upgrade head || true

      - name: Health checks
        shell: bash
        run: |
          echo 'API:'; curl -s http://127.0.0.1:8000/health || true
          echo 'FE :'; curl -s http://127.0.0.1/health || true

      - name: Open firewall ports (Safe)
        shell: bash
        run: |
          echo "=== 安全地开放端口 ==="
          # 只添加端口规则，不影响现有SSH规则
          sudo iptables -C INPUT -p tcp --dport 80 -j ACCEPT 2>/dev/null || sudo iptables -I INPUT -p tcp --dport 80 -j ACCEPT
          sudo iptables -C INPUT -p tcp --dport 8000 -j ACCEPT 2>/dev/null || sudo iptables -I INPUT -p tcp --dport 8000 -j ACCEPT

          echo "=== 检查端口状态 ==="
          netstat -tlnp | grep ":80\|:8000" || echo "端口检查完成"

