name: Deploy Staging

on:
  workflow_dispatch:
    inputs:
      version:
        description: 'Image version tag (e.g., 1.0.2)'
        required: true
        default: '1.0.2'

permissions:
  contents: read

jobs:
  deploy:
    name: SSH deploy to staging
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Deploy via SSH
        uses: appleboy/ssh-action@v1.0.3
        env:
          VERSION: ${{ inputs.version }}
          IMAGE_OWNER: ${{ vars.IMAGE_OWNER || github.repository_owner }}
        with:
          host: ${{ secrets.STAGING_HOST }}
          username: ${{ secrets.STAGING_USER }}
          password: ${{ secrets.STAGING_PASSWORD }}
          port: ${{ secrets.STAGING_PORT || 22 }}
          script: |
            set -euo pipefail
            cd /opt && mkdir -p hive-platform && cd hive-platform

            # Write compose and env files if not present
            if [ ! -f docker-compose.prod.yml ]; then
              cat > docker-compose.prod.yml <<'EOF'
            version: '3.8'
            services:
              postgres:
                image: postgres:14
                container_name: hive-platform-db
                environment:
                  POSTGRES_DB: hive_small_file_db
                  POSTGRES_USER: postgres
                  POSTGRES_PASSWORD: postgres
                volumes:
                  - postgres_data:/var/lib/postgresql/data
                ports: [ "5432:5432" ]
                networks: [ hive-platform ]
              redis:
                image: redis:6-alpine
                container_name: hive-platform-redis
                ports: [ "6379:6379" ]
                volumes:
                  - redis_data:/data
                networks: [ hive-platform ]
              api:
                image: \
                  ghcr.io/${{ env.IMAGE_OWNER }}/hive-small-file-api:${{ inputs.version }}
                container_name: hive-platform-api
                env_file: [ backend/.env ]
                environment:
                  - SENTRY_ENVIRONMENT=staging
                  - AUTO_CREATE_SCHEMA=false
                  - RELOAD=false
                depends_on: [ postgres, redis ]
                ports: [ "8000:8000" ]
                networks: [ hive-platform ]
              celery-worker:
                image: \
                  ghcr.io/${{ env.IMAGE_OWNER }}/hive-small-file-api:${{ inputs.version }}
                container_name: hive-platform-worker
                command: celery -A app.scheduler.celery_app worker --loglevel=info --concurrency=4
                env_file: [ backend/.env ]
                environment: [ "SENTRY_ENVIRONMENT=staging" ]
                depends_on: [ postgres, redis ]
                networks: [ hive-platform ]
              celery-beat:
                image: \
                  ghcr.io/${{ env.IMAGE_OWNER }}/hive-small-file-api:${{ inputs.version }}
                container_name: hive-platform-beat
                command: celery -A app.scheduler.celery_app beat --loglevel=info
                env_file: [ backend/.env ]
                environment: [ "SENTRY_ENVIRONMENT=staging" ]
                depends_on: [ postgres, redis ]
                networks: [ hive-platform ]
              frontend:
                image: \
                  ghcr.io/${{ env.IMAGE_OWNER }}/hive-small-file-frontend:${{ inputs.version }}
                container_name: hive-platform-frontend
                depends_on: [ api ]
                ports: [ "80:80" ]
                networks: [ hive-platform ]
            volumes: { postgres_data: {}, redis_data: {} }
            networks: { hive-platform: { driver: bridge } }
            EOF
            fi

            mkdir -p backend frontend
            if [ ! -f backend/.env ]; then
              cat > backend/.env <<'EOF'
            SERVER_HOST=0.0.0.0
            SERVER_PORT=8000
            RELOAD=false
            DATABASE_URL=postgresql://postgres:postgres@postgres:5432/hive_small_file_db
            REDIS_URL=redis://redis:6379/0
            CELERY_BROKER_URL=redis://redis:6379/1
            CELERY_RESULT_BACKEND=redis://redis:6379/2
            SECRET_KEY=change-me-in-staging
            ACCESS_TOKEN_EXPIRE_MINUTES=1440
            DEFAULT_HIVE_HOST=localhost
            DEFAULT_HIVE_PORT=10000
            DEFAULT_HDFS_URL=http://namenode:9870/webhdfs/v1
            SMALL_FILE_THRESHOLD=134217728
            SENTRY_DSN=
            SENTRY_ENVIRONMENT=staging
            AUTO_CREATE_SCHEMA=false
            DEMO_MODE=false
            EOF
            fi
            if [ ! -f frontend/.env ]; then
              echo 'VITE_API_BASE_URL=/api/v1' > frontend/.env
            fi

            # Login GHCR with PAT secret
            echo '${{ secrets.GHCR_PAT }}' | docker login ghcr.io -u ${{ env.IMAGE_OWNER }} --password-stdin

            # Pull & up
            docker compose -f docker-compose.prod.yml pull
            docker compose -f docker-compose.prod.yml up -d

            # DB migrate (best-effort)
            sleep 10 || true
            docker compose -f docker-compose.prod.yml exec api alembic upgrade head || true

            # Health checks
            echo 'API:'; curl -s http://127.0.0.1:8000/health || true
            echo 'FE:';  curl -s http://127.0.0.1/health || true

