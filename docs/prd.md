# Hive小文件治理平台 - 产品需求文档 (PRD)

**版本**: v1.0
**创建日期**: 2025-10-12
**PRD类型**: Brownfield Consolidation
**作者**: 基于现有《概要设计说明书》和《功能清单》整合
**BMAD版本**: v4

---

## 1. 产品概述

### 1.1 产品愿景

构建一个企业级的Hive/Impala小文件治理平台,解决大数据环境中小文件过多导致的NameNode内存压力、查询性能下降和存储效率低下问题。

### 1.2 核心问题陈述

**当前痛点**:
- NameNode内存压力:每个文件约占用150字节内存,百万级小文件消耗数GB内存
- 查询性能下降:读取100个小文件比读取1个大文件慢10-100倍
- 存储效率降低:HDFS Block默认128MB,小文件无法充分利用存储空间
- 运维成本高:手工治理小文件耗时且易出错

**目标用户**:
- **大数据运维工程师**:监控和治理生产环境小文件问题
- **数据仓库管理员**:优化Hive表存储和查询性能
- **集群管理员**:降低集群资源消耗,提升稳定性

### 1.3 成功指标(KPI)

| 指标 | 基线 | 目标 | 测量方法 |
|-----|------|------|---------|
| 小文件识别准确率 | N/A | >99% | 与实际HDFS扫描结果对比 |
| 扫描性能 | 手工扫描10表/小时 | >100表/分钟 | 自动化扫描统计 |
| 合并任务成功率 | N/A | >95% | 任务执行成功/总数 |
| NameNode内存节省 | N/A | 降低20%+ | 合并前后对比 |
| 查询性能提升 | N/A | 提升30%+ | 典型查询RT对比 |

---

## 2. 功能需求 (Functional Requirements)

### Epic 1: 集群管理 (Cluster Management)

**业务价值**: 支持多CDH/CDP集群统一管理,降低多集群运维复杂度

#### FR-1.1: 集群配置管理
- **用户故事**: 作为大数据运维工程师,我希望能够添加、编辑、删除集群配置,以便统一管理多个生产环境
- **验收标准**:
  - ✅ 支持配置Hive Server2连接(host/port)
  - ✅ 支持配置MetaStore数据库URL(MySQL/PostgreSQL)
  - ✅ 支持配置HDFS NameNode WebHDFS URL
  - ✅ 支持设置小文件阈值(默认128MB,可配置)
  - ✅ 配置变更需记录审计日志
- **优先级**: P0 (Must Have)

#### FR-1.2: 集群连接测试
- **用户故事**: 作为运维工程师,我希望能够测试集群连接状态,以便快速诊断连接问题
- **验收标准**:
  - ✅ 支持测试Hive Server2连接
  - ✅ 支持测试MetaStore数据库连接
  - ✅ 支持测试HDFS WebHDFS API连接
  - ✅ 显示详细的错误信息和诊断建议
  - ✅ 测试结果缓存5分钟避免频繁测试
- **优先级**: P0

#### FR-1.3: 集群健康监控
- **用户故事**: 作为运维工程师,我希望实时监控集群连接状态,以便及时发现问题
- **验收标准**:
  - ✅ 每5分钟自动检测集群连接状态
  - ✅ 连接异常时发送告警(邮件/钉钉/企微)
  - ✅ 展示集群健康度评分(0-100分)
  - ✅ 记录连接状态历史趋势
- **优先级**: P1 (Should Have)

---

### Epic 2: 智能扫描引擎 (Intelligent Scanning)

**业务价值**: 高效扫描海量表,精准识别小文件问题,支撑治理决策

#### FR-2.1: 混合扫描策略
- **用户故事**: 作为数仓管理员,我希望系统能自动选择最优扫描策略,以便快速获取准确的小文件统计
- **验收标准**:
  - ✅ 支持MetaStore直连扫描(表元数据)
  - ✅ 支持HDFS WebHDFS扫描(文件级数据)
  - ✅ 支持Demo模式(无Hive环境时Mock数据)
  - ✅ 自动选择扫描策略:优先MetaStore,降级HDFS,兜底Mock
  - ✅ strict_real模式:强制实连,禁止Mock降级
- **优先级**: P0

#### FR-2.2: 分区表深度扫描
- **用户故事**: 作为数仓管理员,我希望能扫描分区表的每个分区,以便精准定位问题分区
- **验收标准**:
  - ✅ 支持扫描分区表所有分区
  - ✅ 支持分页查询分区统计(默认50条/页,最大200条)
  - ✅ 支持并发扫描分区(默认5并发,可配置1-20)
  - ✅ 分区级小文件统计(文件数/大小/占比)
  - ✅ 支持按分区值排序和筛选
- **优先级**: P0

#### FR-2.3: 增量和批量扫描
- **用户故事**: 作为运维工程师,我希望能批量扫描整个数据库,且支持增量更新,以便高效更新统计数据
- **验收标准**:
  - ✅ 支持单表扫描
  - ✅ 支持数据库级扫描(所有表)
  - ✅ 支持集群级扫描(所有库表)
  - ✅ 支持限制扫描表数(max_tables_per_db参数)
  - ✅ 扫描进度实时追踪(task_id查询进度)
  - ✅ 支持后台异步扫描(Celery任务)
- **优先级**: P0

#### FR-2.4: 扫描日志持久化
- **用户故事**: 作为运维工程师,我希望查看历史扫描日志,以便追踪扫描历史和排查问题
- **验收标准**:
  - ✅ 所有扫描任务记录到scan_task_logs表
  - ✅ 记录扫描开始/结束时间、状态、错误信息
  - ✅ 支持按cluster_id/database/table筛选日志
  - ✅ 日志保留30天(可配置)
  - ✅ 支持导出日志为CSV
- **优先级**: P1

---

### Epic 3: 文件合并引擎 (Merge Engine)

**业务价值**: 自动化合并小文件,降低NameNode压力,提升查询性能

#### FR-3.1: 多策略合并
- **用户故事**: 作为数仓管理员,我希望系统能根据表格式推荐最优合并策略,以便安全高效地合并文件
- **验收标准**:
  - ✅ 支持CONCATENATE策略(TEXTFILE/SEQUENCEFILE/RCFILE)
  - ✅ 支持INSERT OVERWRITE策略(所有格式)
  - ✅ 支持EC编码优化合并(use_ec标志)
  - ✅ 智能推荐合并策略(基于表格式/大小/文件数)
  - ✅ 合并前验证(文件格式兼容性/锁检查/空间检查)
- **优先级**: P0

#### FR-3.2: 安全合并机制
- **用户故事**: 作为数仓管理员,我希望合并过程中保证数据不丢失,且失败能回滚,以便安全执行合并任务
- **验收标准**:
  - ✅ 原子交换机制(临时表->交换->删除原表)
  - ✅ 合并前元数据验证(行数/文件数/大小一致性)
  - ✅ 合并后数据校验(行数对比/抽样校验)
  - ✅ 失败自动回滚(删除临时表/恢复元数据)
  - ✅ 分布式锁防止并发合并同一表
- **优先级**: P0

#### FR-3.3: 任务调度和监控
- **用户故事**: 作为运维工程师,我希望能创建定时合并任务,且实时查看执行进度,以便自动化治理流程
- **验收标准**:
  - ✅ 支持手动创建合并任务
  - ✅ 支持定时调度(Celery Beat)
  - ✅ 支持批量创建任务(基于扫描结果)
  - ✅ 实时进度追踪(WebSocket推送)
  - ✅ 任务状态管理(pending/running/success/failed/cancelled)
  - ✅ 任务日志详细记录(开始/结束时间/合并前后文件数/节省空间)
- **优先级**: P0

---

### Epic 4: 可视化监控 (Dashboard & Visualization)

**业务价值**: 直观展示小文件趋势和治理效果,支撑数据驱动决策

#### FR-4.1: 实时仪表板
- **用户故事**: 作为运维工程师,我希望通过仪表板一览全局小文件情况,以便快速定位问题集群/表
- **验收标准**:
  - ✅ 展示集群级汇总统计(总文件数/小文件数/占比/浪费空间)
  - ✅ 展示TOP10问题表排行(按小文件数/占比/大小)
  - ✅ 展示小文件趋势图(最近7/30天)
  - ✅ 展示文件大小分布(饼图:小文件/中文件/大文件)
  - ✅ 支持按cluster_id筛选
  - ✅ 数据缓存5分钟(Redis)提升性能
- **优先级**: P0

#### FR-4.2: 表详情页
- **用户故事**: 作为数仓管理员,我希望查看表的详细小文件分布,以便决定是否需要合并
- **验收标准**:
  - ✅ 展示表基本信息(数据库/表名/格式/位置/总大小)
  - ✅ 展示文件统计(总文件数/小文件数/平均大小)
  - ✅ 展示分区级统计(如果是分区表)
  - ✅ 展示历史扫描记录(时间序列图)
  - ✅ 支持触发重新扫描
  - ✅ 支持创建合并任务
- **优先级**: P1

#### FR-4.3: 任务管理界面
- **用户故事**: 作为运维工程师,我希望查看所有合并任务的状态,以便跟踪治理进度
- **验收标准**:
  - ✅ 展示任务列表(分页/筛选/排序)
  - ✅ 支持按状态筛选(pending/running/success/failed)
  - ✅ 支持按时间范围筛选
  - ✅ 支持搜索(库名/表名)
  - ✅ 展示任务详情(执行日志/合并前后对比)
  - ✅ 支持手动执行/取消任务
  - ✅ 支持批量导出任务报告
- **优先级**: P0

---

## 3. 非功能需求 (Non-Functional Requirements)

### NFR-1: 性能要求

| 指标 | 目标 | 测量方法 |
|-----|------|---------|
| API响应时间(P95) | <1000ms | Prometheus监控 |
| 仪表板加载时间 | <3s | 前端性能分析 |
| 表扫描速度 | >100表/分钟 | 扫描任务统计 |
| 合并任务并发 | >10任务同时执行 | Celery队列监控 |
| 分区扫描并发 | 5-20可配置 | 扫描任务参数 |

### NFR-2: 可靠性要求

- **数据一致性**: 合并后行数/文件数/大小必须一致,误差<0.1%
- **任务可恢复**: 合并任务失败自动回滚,不影响原表
- **故障隔离**: 单个集群故障不影响其他集群扫描
- **错误追踪**: 所有错误记录到Sentry,保留30天
- **服务可用性**: 99%+ SLA(排除集群本身故障)

### NFR-3: 可扩展性要求

- **集群规模**: 支持管理10+集群
- **表规模**: 支持扫描10K+表/集群
- **文件规模**: 支持扫描百万级文件
- **并发用户**: 支持10+运维人员同时使用
- **水平扩展**: API/Celery Worker可水平扩展

### NFR-4: 安全性要求

- **数据加密**: 集群密码AES加密存储
- **传输安全**: 生产环境强制HTTPS
- **操作审计**: 所有修改操作记录审计日志
- **权限控制**: 只读/操作员/管理员三级权限(待开发)
- **认证机制**: JWT Token认证(待开发)

### NFR-5: 可维护性要求

- **代码质量**: 单文件代码<500行(强制)
- **测试覆盖率**: 核心模块>80%(目标)
- **文档完整性**: 所有公共API有docstring
- **日志规范**: 统一日志格式,分级记录(DEBUG/INFO/WARNING/ERROR)
- **监控告警**: 集成Sentry错误监控+Prometheus指标监控

### NFR-6: 兼容性要求

- **Hive版本**: 支持Hive 2.x/3.x
- **Impala版本**: 支持Impala 2.x/3.x
- **CDP版本**: 支持CDP 7.x
- **MetaStore**: 支持MySQL 8+, PostgreSQL 12+
- **浏览器**: Chrome 90+, Firefox 88+, Edge 90+

---

## 4. 用户场景 (User Scenarios)

### 场景1: 日常小文件监控

**角色**: 大数据运维工程师
**频率**: 每天上班第一件事

**流程**:
1. 登录平台,查看仪表板
2. 检查TOP10问题表,发现`user_logs`表小文件数突增
3. 点击表名查看详情,发现昨天新增分区`dt=2025-10-11`有3000个小文件
4. 创建合并任务,选择CONCATENATE策略
5. 10分钟后合并完成,小文件从3000降至30个

**预期结果**: NameNode内存降低450MB,查询性能提升40%

---

### 场景2: 集群级批量治理

**角色**: 数仓管理员
**频率**: 每周治理日(周五晚上)

**流程**:
1. 选择生产集群CDP-PROD
2. 点击"扫描整个集群",设置max_tables_per_db=100(避免扫描过久)
3. 30分钟后扫描完成,识别出50个问题表
4. 批量创建合并任务(过滤小文件数<100的表)
5. 设置定时执行时间为22:00-6:00(业务低峰期)
6. 第二天查看执行报告,45个成功,5个失败(格式不支持)

**预期结果**: 集群小文件总数从50万降至5万,NameNode内存降低30%

---

### 场景3: 紧急性能问题排查

**角色**: 数仓管理员
**频率**: 生产故障时

**问题**: 业务反馈某查询突然变慢10倍

**流程**:
1. 进入表详情页,查看历史扫描趋势
2. 发现最近3天小文件数从100暴增至5000
3. 检查任务管理页面,发现自动合并任务已暂停(误操作)
4. 立即手动创建合并任务
5. 20分钟后合并完成,通知业务测试

**预期结果**: 查询时间从100s降至10s,问题解决

---

## 5. Epic 和 Story 列表

| Epic ID | Epic名称 | Story数量 | 优先级 | 状态 |
|---------|---------|----------|--------|------|
| EPIC-1 | 集群管理 | 5 | P0 | ✅已完成 |
| EPIC-2 | 智能扫描引擎 | 8 | P0 | ✅已完成 |
| EPIC-3 | 文件合并引擎 | 10 | P0 | 🔄进行中 |
| EPIC-4 | 可视化监控 | 6 | P0 | ✅已完成 |
| EPIC-5 | 任务调度系统 | 7 | P0 | ✅已完成 |
| EPIC-6 | 代码重构(技术债) | 5 | P0 | 🔄进行中 |
| EPIC-7 | 安全认证(待开发) | 9 | P1 | ❌待开发 |
| EPIC-8 | 高级监控(待开发) | 11 | P1 | ❌待开发 |

**注**: 详细Story列表见`docs/epics/`和`docs/stories/`目录(通过BMAD PO Agent拆分生成)

---

## 6. 技术债和已知问题

### 技术债-1: 超大文件拆分(P0)

**问题**: `safe_hive_engine.py`(165KB,约4000行)违反单文件<500行规范
**影响**: 代码可读性差,维护困难,容易引入Bug
**计划**: 拆分为5个模块(MetadataManager/TempTableManager/AtomicSwapHandler/FileCounter/ValidationService)
**Epic**: EPIC-6 Story 1-5
**截止日期**: 2025-10-20

### 技术债-2: 测试覆盖率低(P1)

**问题**: 核心模块缺少单元测试,集成测试不充分
**影响**: 重构时缺少安全网,容易引入回归Bug
**计划**: 补充核心模块单元测试(目标80%覆盖率)
**Epic**: EPIC-6 Story 6
**截止日期**: 2025-10-25

### 技术债-3: 文档滞后(P2)

**问题**: 代码演进快,文档更新滞后,部分API缺少docstring
**影响**: 新团队成员上手慢,运维依赖口头传承
**计划**: 使用BMAD Document Agent补充文档
**截止日期**: 2025-11-01

---

## 7. 里程碑和发布计划

### v1.0 - 核心功能(已完成)
- ✅ 集群管理基础功能
- ✅ 智能扫描引擎
- ✅ CONCATENATE合并策略
- ✅ 基础仪表板
- ✅ 任务调度系统

### v1.1 - 稳定性增强(2025-10-20)
- 🔄 重构超大文件(EPIC-6)
- 🔄 补充单元测试
- 🔄 完善文档
- 🔄 性能优化(缓存/索引)

### v2.0 - 企业级功能(2025-12-01)
- ❌ 安全认证(JWT/RBAC)
- ❌ 高级监控(趋势预测/智能推荐)
- ❌ 多租户支持
- ❌ 操作审计

---

## 8. 风险和缓解措施

### 风险-1: 合并任务失败导致数据丢失

**概率**: 中
**影响**: 高
**缓解措施**:
- 原子交换机制(临时表->交换)
- 合并前后数据校验(行数/大小)
- 失败自动回滚
- 定期备份MetaStore

### 风险-2: 大规模扫描影响集群性能

**概率**: 中
**影响**: 中
**缓解措施**:
- 限流控制(max_tables_per_db参数)
- 并发控制(分区扫描并发度1-20)
- 业务低峰期执行
- 熔断机制(超时/错误率阈值)

### 风险-3: 技术债累积影响新功能开发

**概率**: 高
**影响**: 中
**缓解措施**:
- EPIC-6专项治理技术债
- 引入BMAD QA Agent做质量门禁
- Pre-commit Hook强制检查文件大小
- 每Sprint分配20%时间还技术债

---

## 9. 依赖和前置条件

### 外部依赖
- Hive/Impala集群可访问
- MetaStore数据库可连接
- HDFS WebHDFS API可访问
- Redis 6+可用
- PostgreSQL 12+/MySQL 8+可用

### 内部依赖
- EPIC-6完成前,暂停大规模新功能开发(避免技术债恶化)
- EPIC-7(安全认证)依赖EPIC-6完成(重构后更易扩展权限)

---

## 附录

### A. 术语表

- **小文件**: 文件大小<128MB(可配置)的HDFS文件
- **CONCATENATE**: Hive原生合并命令,适用于文本格式
- **INSERT OVERWRITE**: Hive SQL重写表数据,适用于所有格式
- **MetaStore**: Hive元数据存储数据库(MySQL/PostgreSQL)
- **WebHDFS**: HDFS的HTTP REST API
- **EC编码**: HDFS Erasure Coding纠删码存储

### B. 参考文档

- [Hive小文件治理平台_概要设计说明书](./Hive小文件治理平台_概要设计说明书.md)
- [功能清单](./FEATURE_LIST.md)
- [E2E测试报告](./E2E_TEST_REPORT.md)
- [ADR: HDFS访问和扫描方案](./adr/0001-hdfs-access-and-scan-approach.md)
- [ADR: 统一Celery和Scanner为混合模式](./adr/0003-unify-celery-scanner-to-hybrid.md)

---

**PRD维护者**: 项目技术负责人
**最后更新**: 2025-10-12
**下次评审**: 每Sprint评审会
