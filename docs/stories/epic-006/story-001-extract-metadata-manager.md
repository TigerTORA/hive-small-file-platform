# Story 6.1: æå–MetadataManageræ¨¡å—

**Story ID**: EPIC-6-STORY-001
**Epic**: EPIC-6 ä»£ç é‡æ„(æŠ€æœ¯å€ºæ²»ç†)
**ä¼˜å…ˆçº§**: P0 (Must Do First)
**é¢„è®¡å·¥æœŸ**: 2å¤©
**çŠ¶æ€**: ğŸ“‹ å¾…å¼€å§‹
**è´Ÿè´£äºº**: TBD

---

## 1. User Story

**ä½œä¸º**å¼€å‘è€…,
**æˆ‘å¸Œæœ›**å°†safe_hive_engine.pyä¸­çš„å…ƒæ•°æ®ç®¡ç†é€»è¾‘æå–ä¸ºç‹¬ç«‹çš„MetadataManageræ¨¡å—,
**ä»¥ä¾¿**æé«˜ä»£ç å¯ç»´æŠ¤æ€§,é™ä½æ ¸å¿ƒæ–‡ä»¶å¤æ‚åº¦,é¿å…é‡å¤ä¸Šæ¬¡é‡æ„å¤±è´¥ã€‚

---

## 2. ä¸šåŠ¡ä»·å€¼

### 2.1 å½“å‰é—®é¢˜
- safe_hive_engine.pyæ–‡ä»¶4228è¡Œ,ä¸¥é‡è¿å<500è¡Œè§„èŒƒ
- å…ƒæ•°æ®ç®¡ç†é€»è¾‘(10ä¸ªæ–¹æ³•,~900è¡Œ)ä¸åˆå¹¶é€»è¾‘è€¦åˆ
- ä¸Šæ¬¡é‡æ„å¤±è´¥(commit 840f29b)æ•™è®­:æ–¹æ³•ç­¾åä¸åŒ¹é…ã€ä¾èµ–ç¼ºå¤±

### 2.2 Storyç›®æ ‡
- æå–10ä¸ªå…ƒæ•°æ®ç›¸å…³æ–¹æ³•ä¸ºç‹¬ç«‹æ¨¡å—
- ä¿æŒæ–¹æ³•ç­¾å100%ä¸€è‡´(åŒ…æ‹¬å…³é”®å­—å‚æ•°å’Œé»˜è®¤å€¼)
- ä¸ºåç»­4ä¸ªæ¨¡å—æå–æ‰“ä¸‹åŸºç¡€
- å•å…ƒæµ‹è¯•è¦†ç›–ç‡>80%

### 2.3 æˆåŠŸæŒ‡æ ‡
- [ ] MetadataManageræ¨¡å—ç‹¬ç«‹å¯æµ‹è¯•
- [ ] safe_hive_engine.pyæˆåŠŸå¼•å…¥å¹¶è°ƒç”¨MetadataManager
- [ ] æ‰€æœ‰ç°æœ‰æµ‹è¯•é€šè¿‡(å›å½’æµ‹è¯•)
- [ ] ä»£ç è¦†ç›–ç‡>80%

---

## 3. éªŒæ”¶æ ‡å‡† (Acceptance Criteria)

### AC-1: åˆ›å»ºç‹¬ç«‹æ¨¡å—æ–‡ä»¶
- [ ] åˆ›å»º`backend/app/engines/safe_hive_metadata_manager.py`
- [ ] æ–‡ä»¶åŒ…å«`SafeHiveMetadataManager`ç±»
- [ ] ç±»æ–‡æ¡£å­—ç¬¦ä¸²æ¸…æ™°æè¿°èŒè´£

### AC-2: æå–10ä¸ªå…ƒæ•°æ®æ–¹æ³• (åŸºäº/tmp/safe_hive_engine_documented.md)

**å¿…é¡»æå–çš„æ–¹æ³•** (æ–¹æ³•ç­¾åå¿…é¡»100%ä¸€è‡´):

1. **`_get_table_location(database_name: str, table_name: str) -> Optional[str]`**
   - è·å–è¡¨çš„HDFSè·¯å¾„
   - ä¾èµ–: HiveMetastoreConnector

2. **`_table_exists(database_name: str, table_name: str) -> bool`**
   - æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
   - ä¾èµ–: HiveMetastoreConnector

3. **`_is_partitioned_table(database_name: str, table_name: str) -> bool`**
   - æ£€æŸ¥æ˜¯å¦ä¸ºåˆ†åŒºè¡¨
   - ä¾èµ–: HiveMetastoreConnector

4. **`_get_table_partitions(database_name: str, table_name: str) -> List[str]`**
   - è·å–è¡¨çš„æ‰€æœ‰åˆ†åŒº
   - ä¾èµ–: HiveMetastoreConnector

5. **`_get_table_format_info(database_name: str, table_name: str) -> Dict[str, Any]`**
   - è·å–è¡¨çš„æ ¼å¼ä¿¡æ¯(TEXTFILE/ORC/PARQUETç­‰)
   - è¿”å›æ ¼å¼: `{"InputFormat": str, "OutputFormat": str, "SerdeInfo": dict}`

6. **`_get_table_columns(database_name: str, table_name: str) -> Tuple[List[str], List[str]]`**
   - è·å–è¡¨çš„åˆ—ä¿¡æ¯
   - è¿”å›: (æ™®é€šåˆ—åˆ—è¡¨, åˆ†åŒºåˆ—åˆ—è¡¨)

7. **`_is_unsupported_table_type(fmt: Dict) -> bool`**
   - æ£€æŸ¥è¡¨æ ¼å¼æ˜¯å¦ä¸æ”¯æŒåˆå¹¶
   - å‚æ•°fmt: æ¥è‡ª_get_table_format_infoçš„è¿”å›å€¼

8. **`_unsupported_reason(fmt: Dict) -> str`**
   - è¿”å›ä¸æ”¯æŒçš„åŸå› æè¿°
   - å‚æ•°fmt: æ¥è‡ª_get_table_format_infoçš„è¿”å›å€¼

9. **`_infer_storage_format_name(fmt: Dict) -> str`**
   - æ¨æ–­å­˜å‚¨æ ¼å¼åç§°(TEXTFILE/ORC/PARQUET)
   - å‚æ•°fmt: æ¥è‡ª_get_table_format_infoçš„è¿”å›å€¼

10. **`_infer_table_compression(fmt: Dict, storage_format: str) -> str`**
    - æ¨æ–­è¡¨çš„å‹ç¼©æ ¼å¼(SNAPPY/GZIP/LZOç­‰)
    - å‚æ•°:
      - fmt: æ¥è‡ª_get_table_format_infoçš„è¿”å›å€¼
      - storage_format: æ¥è‡ª_infer_storage_format_nameçš„è¿”å›å€¼

**å…³é”®è¦æ±‚**:
- âœ… æ–¹æ³•ç­¾å100%ä¸€è‡´(å‚æ•°åã€ç±»å‹ã€é»˜è®¤å€¼)
- âœ… è¿”å›å€¼ç±»å‹100%ä¸€è‡´
- âœ… å¼‚å¸¸å¤„ç†é€»è¾‘100%ä¿ç•™
- âœ… æ—¥å¿—è®°å½•é€»è¾‘100%ä¿ç•™

### AC-3: ä¾èµ–æ³¨å…¥

**æ„é€ å‡½æ•°ç­¾å**:
```python
class SafeHiveMetadataManager:
    def __init__(
        self,
        hive_connector: HiveMetastoreConnector,
        path_resolver: HivePartitionPathResolver
    ):
        self.hive_connector = hive_connector
        self.path_resolver = path_resolver
```

**ä¾èµ–æ¸…å•**:
- `HiveMetastoreConnector`: Hive MetaStoreè¿æ¥å™¨
- `HivePartitionPathResolver`: åˆ†åŒºè·¯å¾„è§£æå™¨

### AC-4: å•å…ƒæµ‹è¯•

**æµ‹è¯•æ–‡ä»¶**: `backend/tests/engines/test_safe_hive_metadata_manager.py`

**å¿…é¡»è¦†ç›–çš„æµ‹è¯•åœºæ™¯**:
1. æµ‹è¯•_get_table_location - æ­£å¸¸è¡¨
2. æµ‹è¯•_get_table_location - è¡¨ä¸å­˜åœ¨
3. æµ‹è¯•_table_exists - å­˜åœ¨/ä¸å­˜åœ¨
4. æµ‹è¯•_is_partitioned_table - åˆ†åŒºè¡¨/éåˆ†åŒºè¡¨
5. æµ‹è¯•_get_table_partitions - æœ‰åˆ†åŒº/æ— åˆ†åŒº
6. æµ‹è¯•_get_table_format_info - TEXTFILE/ORC/PARQUET
7. æµ‹è¯•_get_table_columns - åŒ…å«åˆ†åŒºåˆ—
8. æµ‹è¯•_is_unsupported_table_type - ä¸æ”¯æŒçš„æ ¼å¼
9. æµ‹è¯•_infer_storage_format_name - å„ç§æ ¼å¼æ¨æ–­
10. æµ‹è¯•_infer_table_compression - å„ç§å‹ç¼©æ¨æ–­

**è¦†ç›–ç‡è¦æ±‚**: >80%

### AC-5: ä¸»å¼•æ“é›†æˆ

**ä¿®æ”¹safe_hive_engine.py**:
```python
class SafeHiveMergeEngine:
    def __init__(self, cluster_id: int):
        # ... ç°æœ‰ä»£ç  ...

        # æ–°å¢: ä¾èµ–æ³¨å…¥MetadataManager
        self.metadata_manager = SafeHiveMetadataManager(
            hive_connector=self.hive_connector,
            path_resolver=self.path_resolver
        )

    def execute_merge(self, task: MergeTask, db_session: Session) -> Dict[str, Any]:
        # æ›¿æ¢æ‰€æœ‰self._get_table_locationè°ƒç”¨ä¸º:
        # self.metadata_manager._get_table_location(...)

        # æ›¿æ¢æ‰€æœ‰self._is_partitioned_tableè°ƒç”¨ä¸º:
        # self.metadata_manager._is_partitioned_table(...)

        # ... å…¶ä»–8ä¸ªæ–¹æ³•åŒç† ...
```

**å…³é”®æ£€æŸ¥ç‚¹**:
- [ ] safe_hive_engine.pyä¸­åˆ é™¤10ä¸ªåŸæ–¹æ³•
- [ ] æ‰€æœ‰è°ƒç”¨ç‚¹ä¿®æ”¹ä¸º`self.metadata_manager.æ–¹æ³•å(...)`
- [ ] execute_mergeçš„3ä¸ªåˆ†æ”¯é€»è¾‘ä¸å—å½±å“

### AC-6: å›å½’æµ‹è¯•

**å¿…é¡»é€šè¿‡çš„ç°æœ‰æµ‹è¯•**:
- [ ] `test_execute_merge_non_partitioned_table` (æ•´è¡¨åˆå¹¶)
- [ ] `test_execute_merge_with_partition_filter` (åˆ†åŒºçº§åˆå¹¶)
- [ ] `test_execute_merge_full_table_partitioned` (åˆ†åŒºè¡¨æ•´è¡¨åˆå¹¶)
- [ ] `test_validate_task` (ä»»åŠ¡éªŒè¯)

**å¦‚æœæµ‹è¯•å¤±è´¥**:
- ç«‹å³å›æ»šä¿®æ”¹
- åˆ†æå¤±è´¥åŸå› 
- ä¿®å¤åé‡æ–°æµ‹è¯•

---

## 4. æŠ€æœ¯å®ç°è¦ç‚¹

### 4.1 æ–¹æ³•æå–æ­¥éª¤ (é˜²æ­¢ä¸Šæ¬¡å¤±è´¥)

**Step 1: æå–å‰å‡†å¤‡**
1. å¤‡ä»½safe_hive_engine.py: `cp safe_hive_engine.py safe_hive_engine.py.backup`
2. è¿è¡Œæ‰€æœ‰ç°æœ‰æµ‹è¯•,ç¡®ä¿å½“å‰çŠ¶æ€æ­£å¸¸
3. ä½¿ç”¨mypyæ£€æŸ¥ç±»å‹æ³¨è§£: `mypy backend/app/engines/safe_hive_engine.py`

**Step 2: åˆ›å»ºæ–°æ¨¡å—**
1. åˆ›å»º`safe_hive_metadata_manager.py`
2. å¤åˆ¶(ä¸æ˜¯ç§»åŠ¨)10ä¸ªæ–¹æ³•åˆ°æ–°æ–‡ä»¶
3. æ·»åŠ ç±»å‹æ³¨è§£å’Œæ–‡æ¡£å­—ç¬¦ä¸²
4. å®ç°æ„é€ å‡½æ•°ä¾èµ–æ³¨å…¥

**Step 3: ç¼–å†™å•å…ƒæµ‹è¯•**
1. åˆ›å»º`test_safe_hive_metadata_manager.py`
2. ä¸º10ä¸ªæ–¹æ³•ç¼–å†™ç‹¬ç«‹æµ‹è¯•
3. ä½¿ç”¨Mockéš”ç¦»ä¾èµ–(HiveMetastoreConnector)
4. è¿è¡Œæµ‹è¯•: `pytest backend/tests/engines/test_safe_hive_metadata_manager.py -v`

**Step 4: é›†æˆåˆ°ä¸»å¼•æ“**
1. åœ¨safe_hive_engine.pyçš„__init__ä¸­æ³¨å…¥MetadataManager
2. é€ä¸ªæ›¿æ¢æ–¹æ³•è°ƒç”¨(self._xxx -> self.metadata_manager._xxx)
3. æ¯æ›¿æ¢5ä¸ªæ–¹æ³•,è¿è¡Œä¸€æ¬¡å›å½’æµ‹è¯•
4. å…¨éƒ¨æ›¿æ¢å®Œæˆå,åˆ é™¤åŸ10ä¸ªæ–¹æ³•

**Step 5: éªŒè¯**
1. è¿è¡Œæ‰€æœ‰å•å…ƒæµ‹è¯•: `pytest backend/tests/engines/ -v`
2. è¿è¡Œè¦†ç›–ç‡æ£€æŸ¥: `pytest --cov=backend/app/engines/safe_hive_metadata_manager`
3. è¿è¡Œmypyé™æ€æ£€æŸ¥: `mypy backend/app/engines/`
4. è¿è¡ŒE2Eæµ‹è¯•(å¦‚æœæœ‰)

### 4.2 å…³é”®é£é™©ç‚¹

**é£é™©-1: æ–¹æ³•ç­¾åä¸åŒ¹é…** (ä¸Šæ¬¡å¤±è´¥åŸå› #3)
- **ç¤ºä¾‹**: ä¸Šæ¬¡ä½¿ç”¨äº†keyword-onlyå‚æ•°,ä½†ä¸»å¼•æ“ä¼ ä½ç½®å‚æ•°
- **ç¼“è§£**: é€è¡Œå¯¹ç…§`/tmp/safe_hive_engine_documented.md`ä¸­çš„ç­¾å
- **éªŒè¯**: ä½¿ç”¨mypyé™æ€æ£€æŸ¥

**é£é™©-2: ä¾èµ–æ–¹æ³•é—æ¼** (ä¸Šæ¬¡å¤±è´¥åŸå› #4)
- **ç¤ºä¾‹**: `_get_table_format_info`å¯èƒ½è°ƒç”¨å…¶ä»–ç§æœ‰æ–¹æ³•
- **ç¼“è§£**: ä½¿ç”¨IDEçš„"Find Usages"æ‰¾åˆ°æ‰€æœ‰ä¾èµ–
- **éªŒè¯**: å•å…ƒæµ‹è¯•è¦†ç›–æ‰€æœ‰è°ƒç”¨è·¯å¾„

**é£é™©-3: execute_mergeè°ƒç”¨è·¯å¾„ç ´å** (ä¸Šæ¬¡å¤±è´¥åŸå› #1)
- **ç¤ºä¾‹**: execute_mergeçš„3ä¸ªåˆ†æ”¯å¯èƒ½è°ƒç”¨å…ƒæ•°æ®æ–¹æ³•
- **ç¼“è§£**: ä¸ºexecute_mergeç¼–å†™å®Œæ•´é›†æˆæµ‹è¯•(å…ˆäºæå–)
- **éªŒè¯**: å›å½’æµ‹è¯•è¦†ç›–3ä¸ªåˆ†æ”¯

### 4.3 ä¾èµ–å…³ç³»å›¾

```mermaid
graph TD
    A[SafeHiveMergeEngine] -->|ä¾èµ–æ³¨å…¥| B[SafeHiveMetadataManager]
    B -->|ä¾èµ–| C[HiveMetastoreConnector]
    B -->|ä¾èµ–| D[HivePartitionPathResolver]

    B -->|æä¾›10ä¸ªæ–¹æ³•| E[execute_merge]
    E -->|è°ƒç”¨| F[_get_table_format_info]
    E -->|è°ƒç”¨| G[_is_partitioned_table]
    E -->|è°ƒç”¨| H[_get_table_location]
```

---

## 5. æµ‹è¯•è®¾è®¡

### 5.1 å•å…ƒæµ‹è¯•ç”¨ä¾‹ (åŸºäºBMAD QAè¦æ±‚)

**æµ‹è¯•æ–‡ä»¶**: `backend/tests/engines/test_safe_hive_metadata_manager.py`

```python
import pytest
from unittest.mock import Mock, MagicMock
from backend.app.engines.safe_hive_metadata_manager import SafeHiveMetadataManager

class TestSafeHiveMetadataManager:
    @pytest.fixture
    def mock_hive_connector(self):
        return Mock()

    @pytest.fixture
    def mock_path_resolver(self):
        return Mock()

    @pytest.fixture
    def metadata_manager(self, mock_hive_connector, mock_path_resolver):
        return SafeHiveMetadataManager(
            hive_connector=mock_hive_connector,
            path_resolver=mock_path_resolver
        )

    # æµ‹è¯•ç”¨ä¾‹1: _get_table_location - æ­£å¸¸è¡¨
    def test_get_table_location_success(self, metadata_manager, mock_hive_connector):
        # Given
        mock_hive_connector.get_table_location.return_value = "/user/hive/warehouse/test_db.db/test_table"

        # When
        result = metadata_manager._get_table_location("test_db", "test_table")

        # Then
        assert result == "/user/hive/warehouse/test_db.db/test_table"
        mock_hive_connector.get_table_location.assert_called_once_with("test_db", "test_table")

    # æµ‹è¯•ç”¨ä¾‹2: _get_table_location - è¡¨ä¸å­˜åœ¨
    def test_get_table_location_not_exists(self, metadata_manager, mock_hive_connector):
        # Given
        mock_hive_connector.get_table_location.return_value = None

        # When
        result = metadata_manager._get_table_location("test_db", "non_exist_table")

        # Then
        assert result is None

    # æµ‹è¯•ç”¨ä¾‹3: _is_partitioned_table - åˆ†åŒºè¡¨
    def test_is_partitioned_table_true(self, metadata_manager, mock_hive_connector):
        # Given
        mock_hive_connector.get_partitions.return_value = ["dt=2025-10-11", "dt=2025-10-12"]

        # When
        result = metadata_manager._is_partitioned_table("test_db", "partitioned_table")

        # Then
        assert result is True

    # æµ‹è¯•ç”¨ä¾‹4: _get_table_format_info - ORCæ ¼å¼
    def test_get_table_format_info_orc(self, metadata_manager, mock_hive_connector):
        # Given
        mock_hive_connector.get_table_format.return_value = {
            "InputFormat": "org.apache.hadoop.hive.ql.io.orc.OrcInputFormat",
            "OutputFormat": "org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat",
            "SerdeInfo": {"serializationLib": "org.apache.hadoop.hive.ql.io.orc.OrcSerde"}
        }

        # When
        result = metadata_manager._get_table_format_info("test_db", "orc_table")

        # Then
        assert "OrcInputFormat" in result["InputFormat"]
        assert result["SerdeInfo"]["serializationLib"].endswith("OrcSerde")

    # æµ‹è¯•ç”¨ä¾‹5: _infer_storage_format_name - PARQUET
    def test_infer_storage_format_parquet(self, metadata_manager):
        # Given
        fmt = {
            "InputFormat": "org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat",
            "OutputFormat": "org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat"
        }

        # When
        result = metadata_manager._infer_storage_format_name(fmt)

        # Then
        assert result == "PARQUET"

    # ... ç»§ç»­5-10ä¸ªæµ‹è¯•ç”¨ä¾‹ ...
```

**è¦†ç›–ç‡ç›®æ ‡**: æ¯ä¸ªæ–¹æ³•è‡³å°‘2ä¸ªæµ‹è¯•ç”¨ä¾‹,æ€»è¦†ç›–ç‡>80%

### 5.2 é›†æˆæµ‹è¯•ç”¨ä¾‹ (safe_hive_engine.py)

**æµ‹è¯•åœºæ™¯**: éªŒè¯MetadataManageré›†æˆåexecute_mergeæ­£å¸¸å·¥ä½œ

```python
def test_execute_merge_with_metadata_manager(self, mock_engine):
    # Given: åˆ›å»ºåˆå¹¶ä»»åŠ¡
    task = MergeTask(
        database="test_db",
        table="test_table",
        partition_filter=None,
        target_format="ORC"
    )

    # When: æ‰§è¡Œåˆå¹¶
    result = mock_engine.execute_merge(task, db_session)

    # Then: éªŒè¯è°ƒç”¨äº†MetadataManageræ–¹æ³•
    mock_engine.metadata_manager._get_table_format_info.assert_called()
    mock_engine.metadata_manager._is_partitioned_table.assert_called()
    assert result["success"] is True
```

---

## 6. DoD (Definition of Done)

### ä»£ç å®Œæˆæ ‡å‡†
- [ ] SafeHiveMetadataManagerç±»åˆ›å»ºå¹¶é€šè¿‡mypyæ£€æŸ¥
- [ ] 10ä¸ªæ–¹æ³•æå–å®Œæˆ,ç­¾å100%ä¸€è‡´
- [ ] safe_hive_engine.pyæˆåŠŸé›†æˆMetadataManager
- [ ] safe_hive_engine.pyåˆ é™¤åŸ10ä¸ªæ–¹æ³•

### æµ‹è¯•å®Œæˆæ ‡å‡†
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡>80%
- [ ] æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡
- [ ] æ‰€æœ‰å›å½’æµ‹è¯•é€šè¿‡
- [ ] é›†æˆæµ‹è¯•é€šè¿‡

### æ–‡æ¡£å®Œæˆæ ‡å‡†
- [ ] SafeHiveMetadataManagerç±»æ–‡æ¡£å­—ç¬¦ä¸²å®Œæ•´
- [ ] 10ä¸ªæ–¹æ³•æ–‡æ¡£å­—ç¬¦ä¸²å®Œæ•´
- [ ] æ›´æ–°architecture.md(å¦‚éœ€è¦)

### è´¨é‡é—¨ç¦
- [ ] Mypyé™æ€æ£€æŸ¥é€šè¿‡
- [ ] Pre-commit Hooké€šè¿‡
- [ ] Code Reviewé€šè¿‡
- [ ] BMAD QAè¯„å®¡é€šè¿‡(`/BMadqa *review`)

---

## 7. å‚è€ƒèµ„æ–™

### å…³é”®æ–‡æ¡£
- **æ–¹æ³•ç­¾åå‚è€ƒ**: `/tmp/safe_hive_engine_documented.md` (Section A - MetadataManager)
- **ä¸Šæ¬¡å¤±è´¥åˆ†æ**: Git commit 840f29b
- **BMAD BrownfieldæŒ‡å—**: `.bmad-core/working-in-the-brownfield.md`
- **æµ‹è¯•è§„èŒƒ**: `docs/architecture.md` ç¬¬9ç« 

### ç›¸å…³ä»£ç 
- **ä¸»å¼•æ“æ–‡ä»¶**: `backend/app/engines/safe_hive_engine.py`
- **ä¾èµ–æ¥å£**: `backend/app/engines/connection_manager.py`
- **è·¯å¾„è§£æå™¨**: `backend/app/engines/hive_partition_path_resolver.py`

---

## 8. æ—¶é—´çº¿

| é˜¶æ®µ | ä»»åŠ¡ | æ—¶é—´ |
|-----|-----|------|
| Day 1 ä¸Šåˆ | åˆ›å»ºæ¨¡å—+æå–æ–¹æ³•+ç¼–å†™å•å…ƒæµ‹è¯• | 4å°æ—¶ |
| Day 1 ä¸‹åˆ | è¿è¡Œå•å…ƒæµ‹è¯•+ä¿®å¤Bug | 4å°æ—¶ |
| Day 2 ä¸Šåˆ | é›†æˆåˆ°ä¸»å¼•æ“+å›å½’æµ‹è¯• | 4å°æ—¶ |
| Day 2 ä¸‹åˆ | ä»£ç å®¡æŸ¥+æ–‡æ¡£è¡¥å……+QAè¯„å®¡ | 4å°æ—¶ |

**æ€»å·¥æ—¶**: 2å¤© (16å°æ—¶)

---

**Storyåˆ›å»ºæ—¶é—´**: 2025-10-12
**Storyè´Ÿè´£äºº**: TBD
**Epicè´Ÿè´£äºº**: TBD
**ä¸‹æ¬¡è¯„å®¡**: Sprint Planning
